{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_2_ws",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBQTMxDRE_nL"
      },
      "source": [
        "# Download the dataset.\n",
        "!curl -fsS https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip -o ./trainDevTestTrees_PTB.zip\n",
        "!unzip -q -o -d ./ ./trainDevTestTrees_PTB.zip\n",
        "!rm -f ./trainDevTestTrees_PTB.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhhSca_NFKnu"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from torch import nn\n",
        "def loadsst(path):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    with open(path, 'r') as file:\n",
        "        # Quick, dirty, and improper S-expression parsing.\n",
        "        for line in file.readlines():\n",
        "            soup = line.split()\n",
        "            ys.append(int(soup[0].lstrip('(')))\n",
        "            tokens = []\n",
        "            for chunk in soup[2:]:\n",
        "                if not chunk.endswith(\")\"):\n",
        "                    continue\n",
        "                tokens.append(chunk.rstrip( ')'))\n",
        "            xs.append(tokens)\n",
        "    return xs, ys\n",
        "\n",
        "ssttrainxs, ssttrainys = loadsst(\"./trees/train.txt\")\n",
        "sstvalidxs, sstvalidys = loadsst(\"./trees/dev.txt\")\n",
        "ssttestxs, ssttestys   = loadsst(\"./trees/test.txt\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnh4ZMcBI8xL"
      },
      "source": [
        "  #Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INQe7vlmFNFM"
      },
      "source": [
        "#Alphabet creation\n",
        "corpus = ''.join( ' '.join(s) for s in ssttrainxs + ssttestxs + sstvalidxs)\n",
        "alphabet = list(set(corpus))\n",
        "#character to value dictionnary\n",
        "char2val= {}\n",
        "for i in range(len(alphabet)):\n",
        "  char2val[alphabet[i]] = i\n",
        "\n",
        "#Joining all the sentences together \n",
        "ssttrainxs =  ''.join( ' '.join(s) for s in ssttrainxs)\n",
        "sstvalidxs =  ''.join( ' '.join(s) for s in sstvalidxs)\n",
        "ssttestxs =  ''.join( ' '.join(s) for s in ssttestxs)\n",
        "\n",
        "#changing character to their value correspondant reffering to the alphabet\n",
        "ssttrainxs = [char2val[char] for char in ssttrainxs]\n",
        "sstvalidxs = [char2val[char] for char in sstvalidxs]\n",
        "ssttestxs = [char2val[char] for char in ssttestxs]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbeYZxrJJnwi"
      },
      "source": [
        "# Hyper-parameters \n",
        "batch_size = 64\n",
        "sequence_length = 128 \n",
        "hidden_size = 512\n",
        "num_layers = 2    \n",
        "num_epochs = 64\n",
        "learning_rate = 0.001\n",
        "mlp_layers = 2\n",
        "MLP1 = 256\n",
        "MLP2 = 256\n",
        "\n",
        "\n",
        "input_size = len(alphabet) #one hot label encoding vector \n",
        "num_classes = len(alphabet)\n",
        "Data_length = int(len(ssttrainxs) / sequence_length)\n",
        "\n",
        "dev_length = int(len(sstvalidxs) / sequence_length)\n",
        "test_length = int(len(ssttestxs) / sequence_length)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvm7ddnJI-Ci"
      },
      "source": [
        "'''Slicing the inputs for later use of batches'''\n",
        "\n",
        "#ensuring the last element sentence has the same sequence_length\n",
        "if len(ssttrainxs) % sequence_length != 0:\n",
        "  cut = len(ssttrainxs) % sequence_length\n",
        "  ssttrainxs[:-cut]\n",
        "\n",
        "if len(ssttestxs) % sequence_length != 0:\n",
        "  cut = len(ssttestxs) % sequence_length\n",
        "  ssttestxs[:-cut]\n",
        "\n",
        "if len(sstvalidxs) % sequence_length != 0:\n",
        "  cut = len(sstvalidxs) % sequence_length\n",
        "  sstvalidxs[:-cut]\n",
        "\n",
        "#slicing in sequence_length size// \n",
        "trainX = [ssttrainxs[(i*sequence_length - sequence_length):(i*sequence_length - 1)] for i in range(1, Data_length + 1)]\n",
        "testX = [ssttestxs[(i*sequence_length - sequence_length):(i*sequence_length - 1)] for i in range(1, test_length + 1)]\n",
        "devX = [sstvalidxs[(i*sequence_length - sequence_length):(i*sequence_length - 1)] for i in range(1, dev_length + 1)]\n",
        "\n",
        "#Creating  output\n",
        "trainY = [ssttrainxs[(i*sequence_length - sequence_length + 1):(i*sequence_length)] for i in range(1, Data_length + 1)]\n",
        "devY = [sstvalidxs[(i*sequence_length - sequence_length + 1):(i*sequence_length)] for i in range(1, dev_length + 1)]\n",
        "testY = [ssttestxs[(i*sequence_length - sequence_length + 1):(i*sequence_length)] for i in range(1, test_length + 1)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvNvBGxoFQCy"
      },
      "source": [
        "#one hot encoding\n",
        "def one_hot_encoding(training_data, dict_size, seq_len, batch_size):\n",
        "    # Creating zeros array\n",
        "    ohe_matrix = np.zeros((batch_size, seq_len - 1, dict_size), dtype=np.float32)\n",
        "    # inputing the 1 in the right index for ohe\n",
        "    for i in range(batch_size):\n",
        "      for u in range(seq_len - 1):      \n",
        "        ohe_matrix[i, u, training_data[i][u]] = 1\n",
        "    return ohe_matrix\n",
        "\n",
        "training_input = torch.from_numpy(one_hot_encoding(trainX, num_classes, sequence_length, Data_length))\n",
        "training_output = torch.Tensor(trainY)\n",
        "\n",
        "dev_input = torch.from_numpy(one_hot_encoding(devX, num_classes, sequence_length, dev_length))\n",
        "dev_output = torch.Tensor(devY)\n",
        "\n",
        "testing_input = torch.from_numpy(one_hot_encoding(testX, num_classes, sequence_length, test_length))\n",
        "testing_output = torch.Tensor(testY)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as_ywLOuRQyJ"
      },
      "source": [
        "import torch.utils.data as data\n",
        "#use Data loader to generate Data and concatenate inputs and labels\n",
        "training_data = data.DataLoader(np.dstack((training_input, training_output)), batch_size)\n",
        "dev_data = data.DataLoader(np.dstack((dev_input, dev_output)), batch_size)\n",
        "test_data = data.DataLoader(np.dstack((testing_input, testing_output)), batch_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IvOOhrjqCm2"
      },
      "source": [
        "#Vanilla RNN\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)       \n",
        "\n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        hidden.to(device)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, _ = self.rnn(x.to(device), hidden.to(device))\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "      # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "      # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "      hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "      return hidden\n",
        "\n",
        "rnn_model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "def correct(y_pred, y):\n",
        "  prediction_idx = torch.argmax(y_pred, dim=1)\n",
        "  correct = torch.sum(prediction_idx == y)\n",
        "  return correct\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate) \n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "  corrects = 0\n",
        "  for iter_data in training_data:\n",
        "    X = iter_data[:, :, :-1]\n",
        "    Y = iter_data[:, :, -1]\n",
        "    optimizer.zero_grad()\n",
        "    X.to(device)\n",
        "    output_training = rnn_model(X)   \n",
        "    output_training.to(device)\n",
        "    corrects += correct(output_training, Y.view(-1).long().to(device))\n",
        "    loss = criterion(output_training, Y.view(-1).long().to(device))     #loss = criterion(outputs, labels)\n",
        "    loss.backward()  #Backpropagation\n",
        "    optimizer.step()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYnjXUumsDFO"
      },
      "source": [
        "#GRU \n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(GRU, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        # -> x needs to be: (batch_size, seq, input_size)\n",
        "        \n",
        "        # or:\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        hidden.to(device)\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, _ = self.gru(x.to(device), hidden.to(device))       \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "      # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "      #  send the tensor holding the hidden state to the device specified earlier as well\n",
        "      hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "      return hidden\n",
        "\n",
        "gru_model = GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "def correct(y_pred, y):\n",
        "  prediction_idx = torch.argmax(y_pred, dim=1)\n",
        "  correct = torch.sum(prediction_idx == y)\n",
        "  return correct\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.Adam(gru_model.parameters(), lr=learning_rate) \n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "  corrects = 0\n",
        "  for iter_data in training_data:\n",
        "    X = iter_data[:, :, :-1]\n",
        "    Y = iter_data[:, :, -1]\n",
        "    optimizer.zero_grad()\n",
        "    X.to(device)\n",
        "    output_training = gru_model(X)   \n",
        "    output_training.to(device)\n",
        "    corrects += correct(output_training, Y.view(-1).long().to(device))\n",
        "    loss = criterion(output_training, Y.view(-1).long().to(device))     #loss = criterion(outputs, labels)\n",
        "    loss.backward()  #Backpropagation\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cywbc2Kh_81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ede61f3a-8468-48c0-8e01-c6074abea821"
      },
      "source": [
        "'''LSTM and Final model'''\n",
        "#with possible use of 2 and 3 layer MLP transformations\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, MLP_layers = 1, layermlp1 = 128, layermlp2 = 128):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size       \n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        self.MLP = MLP_layers       \n",
        "        self.mlp1 = nn.Linear(hidden_size, layermlp1)\n",
        "        self.mlp2 = nn.Linear(layermlp1, layermlp2)\n",
        "\n",
        "        if MLP_layers == 1:\n",
        "          self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        elif MLP_layers == 2:\n",
        "          self.fc = nn.Linear(layermlp1, num_classes)\n",
        "        else:\n",
        "          self.fc = nn.Linear(layermlp2, num_classes)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "\n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device) \n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, _ = self.lstm(x.to(device), (hidden.to(device), c0.to(device)))\n",
        "\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "\n",
        "\n",
        "        #outputing depending on the MLP layers wanted\n",
        "        if self.MLP == 2:\n",
        "            out = self.mlp1(out)\n",
        "            out = nn.functional.relu(out)\n",
        "        elif self.MLP == 3:\n",
        "            out = self.mlp1(out)\n",
        "            out = nn.functional.relu(out)\n",
        "            out = self.mlp2(out)\n",
        "            out = nn.functional.relu(out)\n",
        "\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "      # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "      # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "      hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "      return hidden\n",
        "\n",
        "\n",
        "def correct(y_pred, y):\n",
        "  prediction_idx = torch.argmax(y_pred, dim=1)\n",
        "  correct = torch.sum(prediction_idx == y)\n",
        "  return correct\n",
        "\n",
        "\n",
        "lstm_model = LSTM(input_size, hidden_size, num_layers, num_classes, mlp_layers, MLP1, MLP2).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate) \n",
        "\n",
        "# Train the model\n",
        "accuracies = []\n",
        "accuracies_dev = []\n",
        "accuracies_test = []\n",
        "loss_training = []\n",
        "loss_validation = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  corrects_dev = 0\n",
        "  corrects = 0\n",
        "  loss2 = 0\n",
        "  for iter_data in training_data:\n",
        "    X = iter_data[:, :, :-1]\n",
        "    Y = iter_data[:, :, -1]\n",
        "    optimizer.zero_grad()\n",
        "    X.to(device)\n",
        "    output_training = lstm_model(X)   \n",
        "    # output_training.to(device)\n",
        "    corrects += correct(output_training, Y.view(-1).long().to(device))\n",
        "    loss = criterion(output_training, Y.view(-1).long().to(device))     #loss = criterion(outputs, labels)\n",
        "    loss.backward()  #Backpropagation\n",
        "    optimizer.step()\n",
        "    loss2 += loss\n",
        "  loss_training.append(loss2)\n",
        "\n",
        "  #validation loop on data \n",
        "  loss_dev2 = 0\n",
        "  for iter_data in dev_data:\n",
        "    X = iter_data[:, :, :-1]\n",
        "    Y = iter_data[:, :, -1]\n",
        "    output_dev = lstm_model(X).to(device)\n",
        "    # output_dev = output_dev.cpu()\n",
        "    corrects_dev += correct(output_dev, Y.view(-1).long().to(device))\n",
        "    loss_dev = criterion(output_dev, Y.view(-1).long().to(device)).item()\n",
        "    loss_dev2 += loss_dev\n",
        "  loss_validation.append(loss_dev2)\n",
        "\n",
        "#plot of validation and training loss\n",
        "plt.plot(np.array(loss_training)/Data_length, label = 'training')\n",
        "plt.plot(np.array(loss_validation)/dev_length, label = 'validation')\n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkt7QfY8Wkzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1319ddd2-c2e8-4b05-c309-5ce2dd6a6350"
      },
      "source": [
        "''' Final accuracy on the training, validation, and test set.'''\r\n",
        "\r\n",
        "#test accuracy\r\n",
        "corrects_test = 0\r\n",
        "for iter_data in test_data:\r\n",
        "  X = iter_data[:, :, :-1]\r\n",
        "  Y = iter_data[:, :, -1]\r\n",
        "  output_test = lstm_model(X)\r\n",
        "  output_test.to(device)\r\n",
        "  corrects_test += correct(output_test, Y.view(-1).long().to(device))\r\n",
        "\r\n",
        "accuracy = corrects/(Data_length * (sequence_length - 1))* 100\r\n",
        "print('Training accuracy = {}%'.format(accuracy))\r\n",
        "\r\n",
        "dev_accuracy = corrects_dev / (dev_length * (sequence_length - 1)) * 100\r\n",
        "print('Validation accuracy = {}%'.format(dev_accuracy))\r\n",
        "\r\n",
        "test_accuracy = corrects_test / (test_length * (sequence_length - 1)) * 100\r\n",
        "print('Testing accuracy = {}%'.format(test_accuracy))\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy = 72.87130737304688%\n",
            "Validation accuracy = 55.95063400268555%\n",
            "Testing accuracy = 55.649261474609375%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWKNlxDPp9vV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fc5535-34fd-46d5-f249-62f6b3c29bb0"
      },
      "source": [
        "''' Sentence creation ''' \r\n",
        "\r\n",
        "#creation of sentences\r\n",
        "test_sentence1 = 'Your father is  '  \r\n",
        "test_sentence2 = 'Hello, this is the end of books and art'\r\n",
        "test_sentence3 = 'I am lacking inspiration '\r\n",
        "test_sentence4 = 'Hello world '\r\n",
        "test_sentence5 = 'Welcome to'\r\n",
        "\r\n",
        "\r\n",
        "#one hot encoding it\r\n",
        "def hot_encode(sentence):\r\n",
        "  ohe = np.zeros([len(sentence), num_classes])\r\n",
        "  for u in range(len(sentence)):    \r\n",
        "    ohe[u, [char2val[char] for char in sentence][u]] = 1\r\n",
        "  return ohe\r\n",
        "#predict the end of a sentence\r\n",
        "def predict_end_sentence(test_sentence, maxlength):\r\n",
        "  ohe1 = hot_encode(test_sentence)\r\n",
        "  char1 = torch.argmax(lstm_model(torch.Tensor(ohe1.reshape(1, len(ohe1), num_classes)))[-1]).item()\r\n",
        "\r\n",
        "  while char1 not in (char2val['.'], char2val['?'], char2val['!']):\r\n",
        "    if ohe1.shape[0] > maxlength:\r\n",
        "      print('errorr')\r\n",
        "      break\r\n",
        "    # print(list(char2val.keys())[list(char2val.values()).index(char1)])\r\n",
        "    test_sentence += list(char2val.keys())[list(char2val.values()).index(char1)]\r\n",
        "    new_row = np.zeros(num_classes)\r\n",
        "    new_row[char1] = 1\r\n",
        "    ohe1 = np.vstack([ohe1, new_row])\r\n",
        "    char1 = torch.argmax(lstm_model(torch.Tensor(ohe1.reshape(1, ohe1.shape[0], num_classes)))[-1]).item()\r\n",
        "\r\n",
        "  return test_sentence + list(char2val.keys())[list(char2val.values()).index(char1)]\r\n",
        "\r\n",
        "#call functions\r\n",
        "print(predict_end_sentence(test_sentence1, 128))\r\n",
        "print(predict_end_sentence(test_sentence2, 128))\r\n",
        "print(predict_end_sentence(test_sentence3, 128))\r\n",
        "print(predict_end_sentence(test_sentence4, 128))\r\n",
        "print(predict_end_sentence(test_sentence5, 128))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your father is  - it also how to make it .\n",
            "Hello, this is the end of books and artificing and over-the-top .\n",
            "I am lacking inspiration .\n",
            "Hello world , but it is the execution it with a frighten , and the characters are not to be for the movie .\n",
            "Welcome to the credits rarrelly light thriller .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuFLqbswHaT4"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}